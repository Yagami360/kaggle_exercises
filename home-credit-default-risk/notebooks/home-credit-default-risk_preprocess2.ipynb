{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!${HOME}\n!${PWD}\n!ls -l","execution_count":9,"outputs":[{"output_type":"stream","text":"/bin/sh: 1: /root: Permission denied\n/bin/sh: 1: /kaggle/working: Permission denied\ntotal 36\n---------- 1 root root 34391 May  6 08:14 __notebook_source__.ipynb\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport argparse\nimport numpy as np\nimport pandas as pd\nimport random\nimport warnings\nimport json\nimport yaml\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport gc\n#from kaggle.api.kaggle_api_extended import KaggleApi\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n#from sklearn.preprocessing import Imputer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import PolynomialFeatures\n\n\n# 機械学習モデル\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nimport xgboost as xgb\nimport lightgbm as lgb\nimport catboost\n","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parser = argparse.ArgumentParser()\nparser.add_argument(\"--exper_name\", default=\"single_model\", help=\"実験名\")\nparser.add_argument(\"--dataset_dir\", type=str, default=\"../input/home-credit-default-risk\")\nparser.add_argument(\"--results_dir\", type=str, default=\"../output/kaggle/working\")\nparser.add_argument(\"--submit_file\", type=str, default=\"submission.csv\")\nparser.add_argument(\"--competition_id\", type=str, default=\"home-credit-default-risk\")\nparser.add_argument(\"--classifier\", choices=[\"logistic\", \"knn\", \"svm\", \"random_forest\", \"bagging\", \"adaboost\", \"xgboost\", \"lightgbm\", \"catboost\", \"mlp\"], default=\"catboost\", help=\"分類器モデルの種類\")\nparser.add_argument('--save_checkpoints_dir', type=str, default=\"checkpoints\", help=\"モデルの保存ディレクトリ\")\nparser.add_argument(\"--params_file\", type=str, default=\"\")\nparser.add_argument('--load_checkpoints_paths', action='append', help=\"モデルの読み込みファイルのパス\")\nparser.add_argument(\"--train_mode\", choices=[\"train\", \"test\", \"eval\"], default=\"train\", help=\"\")\nparser.add_argument('--gdbt_train_type', choices=['train', 'fit'], default=\"fit\", help=\"GDBTの学習タイプ\")\nparser.add_argument(\"--n_splits\", type=int, default=4, help=\"CV での学習用データセットの分割数\")\nparser.add_argument('--onehot_encode', action='store_false')\nparser.add_argument(\"--seed\", type=int, default=71)\nparser.add_argument('--submit', action='store_true')\nparser.add_argument('--eda', action='store_true')\nparser.add_argument('--debug', action='store_true')\n#args = parser.parse_args()\nargs = parser.parse_args(args=[])\n\n# 実験名を自動的に変更\nif( args.exper_name == \"single_model\" ):\n    args.exper_name += \"_\" + args.classifier\n    if( args.params_file != \"\" ):\n        args.exper_name += \"_\" + args.params_file.split(\".\")[0]\n\nfor key, value in vars(args).items():\n    print('%s: %s' % (str(key), str(value)))\n","execution_count":11,"outputs":[{"output_type":"stream","text":"exper_name: single_model_catboost\ndataset_dir: ../input/home-credit-default-risk\nresults_dir: ../output/kaggle/working\nsubmit_file: submission.csv\ncompetition_id: home-credit-default-risk\nclassifier: catboost\nsave_checkpoints_dir: checkpoints\nparams_file: \nload_checkpoints_paths: None\ntrain_mode: train\ngdbt_train_type: fit\nn_splits: 4\nonehot_encode: True\nseed: 71\nsubmit: False\neda: False\ndebug: False\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# データセットの読み込み"},{"metadata":{},"cell_type":"markdown","source":"# 前処理"},{"metadata":{"trusted":true},"cell_type":"code","source":"def agg_dataframe_numric( df_data, agg_column, base_column_name, method = ['count', 'mean', 'max', 'min', 'sum'] ):\n    \"\"\"\n    数値型のデータに対して、同じ値を持つ columns を集約したデータフレームを返す\n    \"\"\"\n    # Remove id variables other than grouping variable\n    for col in df_data:\n        if col != agg_column and 'SK_ID' in col:\n            df_data = df_data.drop(columns = col)\n\n    #df_data_numric = df_data.select_dtypes('number').copy()\n    #df_data_numric[agg_column] = df_data[agg_column].copy()\n    df_data_numric = df_data.select_dtypes('number')\n    df_data_numric[agg_column] = df_data[agg_column]\n\n    # pd.groupby() で集約\n    df_data_numric = df_data_numric.groupby( agg_column, as_index = False ).agg( method ).reset_index()\n\n    # 列名を rename\n    new_columns = [agg_column]\n    for var in df_data_numric.columns.levels[0]:\n        if var != agg_column:            \n            for stat in df_data_numric.columns.levels[1][:-1]:\n                if( var in base_column_name ):\n                    new_columns.append( '%s_%s' % (var, stat))\n                else:\n                    new_columns.append( base_column_name + '_%s_%s' % (var, stat))\n\n    df_data_numric.columns = new_columns\n\n    # １つの値しか持たない列を除外\n    \"\"\"\n    _, idx = np.unique( df_data_numric, axis = 1, return_index=True )\n    df_data_numric = df_data_numric.iloc[:, idx]\n    \"\"\"    \n    return df_data_numric","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def agg_dataframe_categorical( df_data, agg_column, base_column_name, method = ['sum', 'count', 'mean'], one_hot_encode = True ):\n    \"\"\"\n    カテゴリ型のデータに対して、同じ値を持つ columns を集約したデータフレームを返す\n    \"\"\"\n    #df_data_categorical = df_data.select_dtypes('object').copy()\n    #df_data_categorical[agg_column] = df_data[agg_column].copy()\n    df_data_categorical = df_data.select_dtypes('object')\n    df_data_categorical[agg_column] = df_data[agg_column]\n    \n    if( one_hot_encode ):\n        df_data_categorical = pd.get_dummies( df_data_categorical )\n    else:\n        for col in df_data_categorical.columns:\n            # ラベル情報のエンコード\n            if( df_data_categorical[col].dtypes == \"object\" ):\n                label_encoder = LabelEncoder()\n                label_encoder.fit(list(df_data_categorical[col]))\n                df_data_categorical[col] = label_encoder.transform(list(df_data_categorical[col]))\n\n    # pd.groupby() で集約\n    df_data_categorical = df_data_categorical.groupby( agg_column, as_index = False ).agg( method ).reset_index()\n\n    # 列名を rename\n    new_columns = [agg_column]\n    for var in df_data_categorical.columns.levels[0]:\n        if var != agg_column:            \n            for stat in df_data_categorical.columns.levels[1][:-1]:\n                \"\"\"\n                # カテゴリーデータに対しては、sum は count の意味になる\n                if( stat == \"sum\" ):\n                    stat = \"count\"\n                # カテゴリーデータに対しては、mean は count_norm の意味になる\n                elif( stat == \"mean\" ):\n                    stat = \"count_norm\"\n                \"\"\"\n                if( var in base_column_name ):\n                    new_columns.append( '%s_%s' % (var, stat))\n                else:\n                    new_columns.append( base_column_name + '_%s_%s' % (var, stat))\n\n    df_data_categorical.columns = new_columns\n\n    # １つの値しか持たない列を除外\n    \"\"\"\n    _, idx = np.unique( df_data_categorical, axis = 1, return_index=True )\n    df_data_categorical = df_data_categorical.iloc[:, idx]\n    \"\"\"\n\n    return df_data_categorical","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 目的変数\ntarget_name = 'TARGET'\none_hot_encode = args.onehot_encode\n    \n#===========================\n# 無用なデータを除外（結合前）\n#===========================\n# application_{train|test}\ndf_application_train = pd.read_csv( os.path.join(args.dataset_dir, \"application_train.csv\" ) )\ndf_application_test = pd.read_csv( os.path.join(args.dataset_dir, \"application_test.csv\" ) )\n#df_application_train.drop(['FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21'], axis=1, inplace=True)\n#df_application_test.drop(['FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21'], axis=1, inplace=True)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 元データ\ndf_train = df_application_train\ndf_test = df_application_test","execution_count":16,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## PolynomialFeatures"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_poly_features = df_train[ ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'TARGET'] ]\ndf_test_poly_features = df_test[ ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH'] ]\ndf_train_poly_features_target = df_train_poly_features[target_name]\ndf_train_poly_features = df_train_poly_features.drop(columns = [target_name])\n\n# Need to impute missing values\nimputer = SimpleImputer(strategy = 'median')\ndf_train_poly_features = imputer.fit_transform(df_train_poly_features)\ndf_test_poly_features = imputer.transform(df_test_poly_features)\n\n# Train the polynomial features and Transform the features\npoly_transformer = PolynomialFeatures(degree = 3)\npoly_transformer.fit(df_train_poly_features)\ndf_train_poly_features = poly_transformer.transform(df_train_poly_features)\ndf_test_poly_features = poly_transformer.transform(df_test_poly_features)\n\n# Create a dataframe of the features \ndf_train_poly_features = pd.DataFrame(\n    df_train_poly_features, \n    columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH'])\n)\ndf_train_poly_features[target_name] = df_train_poly_features_target\n\n# Put test features into dataframe\ndf_test_poly_features = pd.DataFrame(\n    df_test_poly_features, \n    columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH'])\n)\n","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_poly_features.head()","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"     1  EXT_SOURCE_1  EXT_SOURCE_2  EXT_SOURCE_3  DAYS_BIRTH  EXT_SOURCE_1^2  \\\n0  1.0      0.083037      0.262949      0.139376     -9461.0        0.006895   \n1  1.0      0.311267      0.622246      0.535276    -16765.0        0.096887   \n2  1.0      0.505998      0.555912      0.729567    -19046.0        0.256034   \n3  1.0      0.505998      0.650442      0.535276    -19005.0        0.256034   \n4  1.0      0.505998      0.322738      0.535276    -19932.0        0.256034   \n\n   EXT_SOURCE_1 EXT_SOURCE_2  EXT_SOURCE_1 EXT_SOURCE_3  \\\n0                   0.021834                   0.011573   \n1                   0.193685                   0.166614   \n2                   0.281290                   0.369159   \n3                   0.329122                   0.270849   \n4                   0.163305                   0.270849   \n\n   EXT_SOURCE_1 DAYS_BIRTH  EXT_SOURCE_2^2  ...  EXT_SOURCE_2^2 EXT_SOURCE_3  \\\n0              -785.612748        0.069142  ...                     0.009637   \n1             -5218.396475        0.387190  ...                     0.207254   \n2             -9637.236584        0.309038  ...                     0.225464   \n3             -9616.490669        0.423074  ...                     0.226462   \n4            -10085.550751        0.104160  ...                     0.055754   \n\n   EXT_SOURCE_2^2 DAYS_BIRTH  EXT_SOURCE_2 EXT_SOURCE_3^2  \\\n0                -654.152107                     0.005108   \n1               -6491.237078                     0.178286   \n2               -5885.942404                     0.295894   \n3               -8040.528832                     0.186365   \n4               -2076.117157                     0.092471   \n\n   EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH  EXT_SOURCE_2 DAYS_BIRTH^2  \\\n0                           -346.733022               2.353667e+07   \n1                          -5583.975307               1.748916e+08   \n2                          -7724.580288               2.016572e+08   \n3                          -6616.894625               2.349331e+08   \n4                          -3443.335521               1.282190e+08   \n\n   EXT_SOURCE_3^3  EXT_SOURCE_3^2 DAYS_BIRTH  EXT_SOURCE_3 DAYS_BIRTH^2  \\\n0        0.002707                -183.785678               1.247560e+07   \n1        0.153368               -4803.518937               1.504475e+08   \n2        0.388325              -10137.567875               2.646504e+08   \n3        0.153368               -5445.325225               1.933364e+08   \n4        0.153368               -5710.929881               2.126570e+08   \n\n   DAYS_BIRTH^3  TARGET  \n0 -8.468590e+11       1  \n1 -4.712058e+12       0  \n2 -6.908939e+12       0  \n3 -6.864416e+12       0  \n4 -7.918677e+12       0  \n\n[5 rows x 36 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>EXT_SOURCE_1</th>\n      <th>EXT_SOURCE_2</th>\n      <th>EXT_SOURCE_3</th>\n      <th>DAYS_BIRTH</th>\n      <th>EXT_SOURCE_1^2</th>\n      <th>EXT_SOURCE_1 EXT_SOURCE_2</th>\n      <th>EXT_SOURCE_1 EXT_SOURCE_3</th>\n      <th>EXT_SOURCE_1 DAYS_BIRTH</th>\n      <th>EXT_SOURCE_2^2</th>\n      <th>...</th>\n      <th>EXT_SOURCE_2^2 EXT_SOURCE_3</th>\n      <th>EXT_SOURCE_2^2 DAYS_BIRTH</th>\n      <th>EXT_SOURCE_2 EXT_SOURCE_3^2</th>\n      <th>EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH</th>\n      <th>EXT_SOURCE_2 DAYS_BIRTH^2</th>\n      <th>EXT_SOURCE_3^3</th>\n      <th>EXT_SOURCE_3^2 DAYS_BIRTH</th>\n      <th>EXT_SOURCE_3 DAYS_BIRTH^2</th>\n      <th>DAYS_BIRTH^3</th>\n      <th>TARGET</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.083037</td>\n      <td>0.262949</td>\n      <td>0.139376</td>\n      <td>-9461.0</td>\n      <td>0.006895</td>\n      <td>0.021834</td>\n      <td>0.011573</td>\n      <td>-785.612748</td>\n      <td>0.069142</td>\n      <td>...</td>\n      <td>0.009637</td>\n      <td>-654.152107</td>\n      <td>0.005108</td>\n      <td>-346.733022</td>\n      <td>2.353667e+07</td>\n      <td>0.002707</td>\n      <td>-183.785678</td>\n      <td>1.247560e+07</td>\n      <td>-8.468590e+11</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.311267</td>\n      <td>0.622246</td>\n      <td>0.535276</td>\n      <td>-16765.0</td>\n      <td>0.096887</td>\n      <td>0.193685</td>\n      <td>0.166614</td>\n      <td>-5218.396475</td>\n      <td>0.387190</td>\n      <td>...</td>\n      <td>0.207254</td>\n      <td>-6491.237078</td>\n      <td>0.178286</td>\n      <td>-5583.975307</td>\n      <td>1.748916e+08</td>\n      <td>0.153368</td>\n      <td>-4803.518937</td>\n      <td>1.504475e+08</td>\n      <td>-4.712058e+12</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.505998</td>\n      <td>0.555912</td>\n      <td>0.729567</td>\n      <td>-19046.0</td>\n      <td>0.256034</td>\n      <td>0.281290</td>\n      <td>0.369159</td>\n      <td>-9637.236584</td>\n      <td>0.309038</td>\n      <td>...</td>\n      <td>0.225464</td>\n      <td>-5885.942404</td>\n      <td>0.295894</td>\n      <td>-7724.580288</td>\n      <td>2.016572e+08</td>\n      <td>0.388325</td>\n      <td>-10137.567875</td>\n      <td>2.646504e+08</td>\n      <td>-6.908939e+12</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.505998</td>\n      <td>0.650442</td>\n      <td>0.535276</td>\n      <td>-19005.0</td>\n      <td>0.256034</td>\n      <td>0.329122</td>\n      <td>0.270849</td>\n      <td>-9616.490669</td>\n      <td>0.423074</td>\n      <td>...</td>\n      <td>0.226462</td>\n      <td>-8040.528832</td>\n      <td>0.186365</td>\n      <td>-6616.894625</td>\n      <td>2.349331e+08</td>\n      <td>0.153368</td>\n      <td>-5445.325225</td>\n      <td>1.933364e+08</td>\n      <td>-6.864416e+12</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.505998</td>\n      <td>0.322738</td>\n      <td>0.535276</td>\n      <td>-19932.0</td>\n      <td>0.256034</td>\n      <td>0.163305</td>\n      <td>0.270849</td>\n      <td>-10085.550751</td>\n      <td>0.104160</td>\n      <td>...</td>\n      <td>0.055754</td>\n      <td>-2076.117157</td>\n      <td>0.092471</td>\n      <td>-3443.335521</td>\n      <td>1.282190e+08</td>\n      <td>0.153368</td>\n      <td>-5710.929881</td>\n      <td>2.126570e+08</td>\n      <td>-7.918677e+12</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 36 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge polynomial features into training dataframe\ndf_train_poly_features['SK_ID_CURR'] = df_train['SK_ID_CURR']\ndf_train = pd.merge( df_train, df_train_poly_features, on = 'SK_ID_CURR', how = 'left')\n\n# Merge polnomial features into testing dataframe\ndf_test_poly_features['SK_ID_CURR'] = df_test['SK_ID_CURR']\ndf_test = pd.merge( df_test, df_test_poly_features, on = 'SK_ID_CURR', how = 'left')\n","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"   SK_ID_CURR  TARGET_x NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n0      100002         1         Cash loans           M            N   \n1      100003         0         Cash loans           F            N   \n2      100004         0    Revolving loans           M            Y   \n3      100006         0         Cash loans           F            N   \n4      100007         0         Cash loans           M            N   \n\n  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n0               Y             0          202500.0    406597.5      24700.5   \n1               N             0          270000.0   1293502.5      35698.5   \n2               Y             0           67500.0    135000.0       6750.0   \n3               Y             0          135000.0    312682.5      29686.5   \n4               Y             0          121500.0    513000.0      21865.5   \n\n   ...  EXT_SOURCE_2^2 EXT_SOURCE_3 EXT_SOURCE_2^2 DAYS_BIRTH  \\\n0  ...                     0.009637               -654.152107   \n1  ...                     0.207254              -6491.237078   \n2  ...                     0.225464              -5885.942404   \n3  ...                     0.226462              -8040.528832   \n4  ...                     0.055754              -2076.117157   \n\n  EXT_SOURCE_2 EXT_SOURCE_3^2 EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH  \\\n0                    0.005108                          -346.733022   \n1                    0.178286                         -5583.975307   \n2                    0.295894                         -7724.580288   \n3                    0.186365                         -6616.894625   \n4                    0.092471                         -3443.335521   \n\n  EXT_SOURCE_2 DAYS_BIRTH^2 EXT_SOURCE_3^3  EXT_SOURCE_3^2 DAYS_BIRTH  \\\n0              2.353667e+07       0.002707                -183.785678   \n1              1.748916e+08       0.153368               -4803.518937   \n2              2.016572e+08       0.388325              -10137.567875   \n3              2.349331e+08       0.153368               -5445.325225   \n4              1.282190e+08       0.153368               -5710.929881   \n\n   EXT_SOURCE_3 DAYS_BIRTH^2  DAYS_BIRTH^3  TARGET_y  \n0               1.247560e+07 -8.468590e+11         1  \n1               1.504475e+08 -4.712058e+12         0  \n2               2.646504e+08 -6.908939e+12         0  \n3               1.933364e+08 -6.864416e+12         0  \n4               2.126570e+08 -7.918677e+12         0  \n\n[5 rows x 158 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SK_ID_CURR</th>\n      <th>TARGET_x</th>\n      <th>NAME_CONTRACT_TYPE</th>\n      <th>CODE_GENDER</th>\n      <th>FLAG_OWN_CAR</th>\n      <th>FLAG_OWN_REALTY</th>\n      <th>CNT_CHILDREN</th>\n      <th>AMT_INCOME_TOTAL</th>\n      <th>AMT_CREDIT</th>\n      <th>AMT_ANNUITY</th>\n      <th>...</th>\n      <th>EXT_SOURCE_2^2 EXT_SOURCE_3</th>\n      <th>EXT_SOURCE_2^2 DAYS_BIRTH</th>\n      <th>EXT_SOURCE_2 EXT_SOURCE_3^2</th>\n      <th>EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH</th>\n      <th>EXT_SOURCE_2 DAYS_BIRTH^2</th>\n      <th>EXT_SOURCE_3^3</th>\n      <th>EXT_SOURCE_3^2 DAYS_BIRTH</th>\n      <th>EXT_SOURCE_3 DAYS_BIRTH^2</th>\n      <th>DAYS_BIRTH^3</th>\n      <th>TARGET_y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100002</td>\n      <td>1</td>\n      <td>Cash loans</td>\n      <td>M</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>202500.0</td>\n      <td>406597.5</td>\n      <td>24700.5</td>\n      <td>...</td>\n      <td>0.009637</td>\n      <td>-654.152107</td>\n      <td>0.005108</td>\n      <td>-346.733022</td>\n      <td>2.353667e+07</td>\n      <td>0.002707</td>\n      <td>-183.785678</td>\n      <td>1.247560e+07</td>\n      <td>-8.468590e+11</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100003</td>\n      <td>0</td>\n      <td>Cash loans</td>\n      <td>F</td>\n      <td>N</td>\n      <td>N</td>\n      <td>0</td>\n      <td>270000.0</td>\n      <td>1293502.5</td>\n      <td>35698.5</td>\n      <td>...</td>\n      <td>0.207254</td>\n      <td>-6491.237078</td>\n      <td>0.178286</td>\n      <td>-5583.975307</td>\n      <td>1.748916e+08</td>\n      <td>0.153368</td>\n      <td>-4803.518937</td>\n      <td>1.504475e+08</td>\n      <td>-4.712058e+12</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100004</td>\n      <td>0</td>\n      <td>Revolving loans</td>\n      <td>M</td>\n      <td>Y</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>67500.0</td>\n      <td>135000.0</td>\n      <td>6750.0</td>\n      <td>...</td>\n      <td>0.225464</td>\n      <td>-5885.942404</td>\n      <td>0.295894</td>\n      <td>-7724.580288</td>\n      <td>2.016572e+08</td>\n      <td>0.388325</td>\n      <td>-10137.567875</td>\n      <td>2.646504e+08</td>\n      <td>-6.908939e+12</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100006</td>\n      <td>0</td>\n      <td>Cash loans</td>\n      <td>F</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>135000.0</td>\n      <td>312682.5</td>\n      <td>29686.5</td>\n      <td>...</td>\n      <td>0.226462</td>\n      <td>-8040.528832</td>\n      <td>0.186365</td>\n      <td>-6616.894625</td>\n      <td>2.349331e+08</td>\n      <td>0.153368</td>\n      <td>-5445.325225</td>\n      <td>1.933364e+08</td>\n      <td>-6.864416e+12</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100007</td>\n      <td>0</td>\n      <td>Cash loans</td>\n      <td>M</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>121500.0</td>\n      <td>513000.0</td>\n      <td>21865.5</td>\n      <td>...</td>\n      <td>0.055754</td>\n      <td>-2076.117157</td>\n      <td>0.092471</td>\n      <td>-3443.335521</td>\n      <td>1.282190e+08</td>\n      <td>0.153368</td>\n      <td>-5710.929881</td>\n      <td>2.126570e+08</td>\n      <td>-7.918677e+12</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 158 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Align the dataframes\ndf_train, df_test = df_train.align(df_test, join = 'inner', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## サブ構造の結合[](http://)"},{"metadata":{},"cell_type":"markdown","source":"### [](http://)bureau"},{"metadata":{"trusted":true},"cell_type":"code","source":"# bureau\ndf_bureau = pd.read_csv( os.path.join(args.dataset_dir, \"bureau.csv\" ) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bureau.shape\ndf_bureau.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bureau_agg_numric = agg_dataframe_numric( df_bureau, agg_column = 'SK_ID_CURR', base_column_name = \"bureau\" )\ndf_bureau_agg_categorical = agg_dataframe_categorical( df_bureau, agg_column = 'SK_ID_CURR', base_column_name = \"bureau\", one_hot_encode = one_hot_encode )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( df_bureau_agg_numric.shape )\ndf_bureau_agg_numric.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( df_bureau_agg_categorical.shape )\ndf_bureau_agg_categorical.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 元のデータに統合\ndf_train = pd.merge(df_train, df_bureau_agg_numric, on='SK_ID_CURR', how='left' )\ndf_train = pd.merge(df_train, df_bureau_agg_categorical, on='SK_ID_CURR', how='left' )\ndf_test = pd.merge(df_test, df_bureau_agg_numric, on='SK_ID_CURR', how='left' )\ndf_test = pd.merge(df_test, df_bureau_agg_categorical, on='SK_ID_CURR', how='left' )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 不要になったメモリを解放\ndel df_bureau_agg_numric, df_bureau_agg_categorical\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### bureau_balance"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bureau_balance = pd.read_csv( os.path.join(args.dataset_dir, \"bureau_balance.csv\" ) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bureau_balance.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bureau_balance.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 同じ SK_ID_BUREAU を集約\ndf_bureau_balance_agg_numric = agg_dataframe_numric( df_bureau_balance, agg_column = 'SK_ID_BUREAU', base_column_name = \"bureau_balance\" )\ndf_bureau_balance_agg_categorical = agg_dataframe_categorical( df_bureau_balance, agg_column = 'SK_ID_BUREAU', base_column_name = \"bureau_balance\", one_hot_encode = one_hot_encode )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bureau_balance_agg_numric.shape\ndf_bureau_balance_agg_numric.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 親データ （df_bureau） の 'SK_ID_CURR' に、対応する 'SK_ID_BUREAU' を紐付け\ndf_bureau_balance_agg_numric = df_bureau[['SK_ID_BUREAU', 'SK_ID_CURR']].merge(df_bureau_balance_agg_numric, on = 'SK_ID_BUREAU', how = 'left')\ndf_bureau_balance_agg_categorical = df_bureau[['SK_ID_BUREAU', 'SK_ID_CURR']].merge(df_bureau_balance_agg_categorical, on = 'SK_ID_BUREAU', how = 'left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bureau_balance_agg_numric.shape\ndf_bureau_balance_agg_numric.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# １つの `SK_ID_CURR` に対して、複数の `SK_ID_BUREAU` が存在することになるので、`SK_ID_CURR` を集約\ndf_bureau_balance_agg_numric = agg_dataframe_numric( df_bureau_balance_agg_numric.drop(columns = ['SK_ID_BUREAU']), agg_column = 'SK_ID_CURR', base_column_name = \"bureau_balance\" )\ndf_bureau_balance_agg_categorical = agg_dataframe_numric( df_bureau_balance_agg_categorical.drop(columns = ['SK_ID_BUREAU']), agg_column = 'SK_ID_CURR', base_column_name = \"bureau_balance\" )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bureau_balance_agg_numric.shape\ndf_bureau_balance_agg_numric.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bureau_balance_agg_categorical.shape\ndf_bureau_balance_agg_categorical.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 元のデータに統合\ndf_train = pd.merge(df_train, df_bureau_balance_agg_numric, on='SK_ID_CURR', how='left' )\ndf_train = pd.merge(df_train, df_bureau_balance_agg_categorical, on='SK_ID_CURR', how='left' )\ndf_test = pd.merge(df_test, df_bureau_balance_agg_numric, on='SK_ID_CURR', how='left' )\ndf_test = pd.merge(df_test, df_bureau_balance_agg_categorical, on='SK_ID_CURR', how='left' )\n\nprint( df_train.shape )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 不要になったメモリを解放\ndel df_bureau, df_bureau_balance, df_bureau_balance_agg_numric, df_bureau_balance_agg_categorical\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### previous_application"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_previous_application = pd.read_csv( os.path.join(args.dataset_dir, \"previous_application.csv\" ) )    \ndf_previous_application_agg_numric = agg_dataframe_numric( df_previous_application, agg_column = 'SK_ID_CURR', base_column_name = \"previous_application\" )\ndf_previous_application_agg_categorical = agg_dataframe_categorical( df_previous_application, agg_column = 'SK_ID_CURR', base_column_name = \"previous_application\", one_hot_encode = one_hot_encode )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_previous_application_agg_numric.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_previous_application_agg_categorical.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 元のデータに統合\ndf_train = pd.merge(df_train, df_previous_application_agg_numric, on='SK_ID_CURR', how='left' )\ndf_train = pd.merge(df_train, df_previous_application_agg_categorical, on='SK_ID_CURR', how='left' )\ndf_test = pd.merge(df_test, df_previous_application_agg_numric, on='SK_ID_CURR', how='left' )\ndf_test = pd.merge(df_test, df_previous_application_agg_categorical, on='SK_ID_CURR', how='left' )\n\nprint( df_train.shape )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 不要になったメモリを解放\ndel df_previous_application_agg_numric, df_previous_application_agg_categorical\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### pos_cash_balance"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pos_cash_balance = pd.read_csv( os.path.join(args.dataset_dir, \"POS_CASH_balance.csv\" ) )\n\n# 同じ SK_ID_PREV を集約\ndf_pos_cash_balance_agg_numric = agg_dataframe_numric( df_pos_cash_balance, agg_column = 'SK_ID_PREV', base_column_name = \"pos_cash_balance\" )\ndf_pos_cash_balance_agg_categorical = agg_dataframe_categorical( df_pos_cash_balance, agg_column = 'SK_ID_PREV', base_column_name = \"pos_cash_balance\", one_hot_encode = one_hot_encode )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pos_cash_balance_agg_numric.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pos_cash_balance_agg_categorical.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 親データ の 'SK_ID_CURR' に、対応する 'SK_ID_PREV' を紐付け\ndf_pos_cash_balance_agg_numric = df_previous_application[['SK_ID_PREV', 'SK_ID_CURR']].merge(df_pos_cash_balance_agg_numric, on = 'SK_ID_PREV', how = 'left')\ndf_pos_cash_balance_agg_categorical = df_previous_application[['SK_ID_PREV', 'SK_ID_CURR']].merge(df_pos_cash_balance_agg_categorical, on = 'SK_ID_PREV', how = 'left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pos_cash_balance_agg_numric.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df_pos_cash_balance_agg_categorical.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# １つの `SK_ID_CURR` に対して、複数の `SK_ID_BUREAU` が存在することになるので、`SK_ID_CURR` を集約\ndf_pos_cash_balance_agg_numric = agg_dataframe_numric( df_pos_cash_balance_agg_numric.drop(columns = ['SK_ID_PREV']), agg_column = 'SK_ID_CURR', base_column_name = \"pos_cash_balance\" )\ndf_pos_cash_balance_agg_categorical = agg_dataframe_numric( df_pos_cash_balance_agg_categorical.drop(columns = ['SK_ID_PREV']), agg_column = 'SK_ID_CURR', base_column_name = \"pos_cash_balance\" )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pos_cash_balance_agg_numric.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pos_cash_balance_agg_categorical.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 元のデータに統合\ndf_train = pd.merge(df_train, df_pos_cash_balance_agg_numric, on='SK_ID_CURR', how='left' )\ndf_train = pd.merge(df_train, df_pos_cash_balance_agg_categorical, on='SK_ID_CURR', how='left' )\ndf_test = pd.merge(df_test, df_pos_cash_balance_agg_numric, on='SK_ID_CURR', how='left' )\ndf_test = pd.merge(df_test, df_pos_cash_balance_agg_categorical, on='SK_ID_CURR', how='left' )\n\nprint( df_train.shape )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 不要になったメモリを解放\ndel df_pos_cash_balance, df_pos_cash_balance_agg_numric, df_pos_cash_balance_agg_categorical\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### installments_payments"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_installments_payments = pd.read_csv( os.path.join(args.dataset_dir, \"installments_payments.csv\" ) )\ndf_installments_payments.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 同じ SK_ID_PREV を集約\ndf_installments_payments_agg_numric = agg_dataframe_numric( df_installments_payments, agg_column = 'SK_ID_PREV', base_column_name = \"installments_payments\" )\ndf_installments_payments_agg_numric.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 親データ の 'SK_ID_CURR' に、対応する 'SK_ID_PREV' を紐付け\ndf_installments_payments_agg_numric = df_previous_application[['SK_ID_PREV', 'SK_ID_CURR']].merge(df_installments_payments_agg_numric, on = 'SK_ID_PREV', how = 'left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_installments_payments_agg_numric.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# １つの `SK_ID_CURR` に対して、複数の `SK_ID_BUREAU` が存在することになるので、`SK_ID_CURR` を集約\ndf_installments_payments_agg_numric = agg_dataframe_numric( df_installments_payments_agg_numric.drop(columns = ['SK_ID_PREV']), agg_column = 'SK_ID_CURR', base_column_name = \"installments_payments\" )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_installments_payments_agg_numric.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 元のデータに統合\ndf_train = pd.merge(df_train, df_installments_payments_agg_numric, on='SK_ID_CURR', how='left' )\ndf_test = pd.merge(df_test, df_installments_payments_agg_numric, on='SK_ID_CURR', how='left' )\n\nprint( df_train.shape )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 不要になったメモリを解放\ndel df_installments_payments, df_installments_payments_agg_numric\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### credit_card_balance"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_credit_card_balance = pd.read_csv( os.path.join(args.dataset_dir, \"credit_card_balance.csv\" ) )\ndf_credit_card_balance.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 同じ SK_ID_PREV を集約\ndf_credit_card_balance_agg_numric = agg_dataframe_numric( df_credit_card_balance, agg_column = 'SK_ID_PREV', base_column_name = \"credit_card_balance\" )\ndf_credit_card_balance_agg_categorical = agg_dataframe_categorical( df_credit_card_balance, agg_column = 'SK_ID_PREV', base_column_name = \"credit_card_balance\", one_hot_encode = one_hot_encode )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 親データ の 'SK_ID_CURR' に、対応する 'SK_ID_PREV' を紐付け\ndf_credit_card_balance_agg_numric = df_previous_application[['SK_ID_PREV', 'SK_ID_CURR']].merge(df_credit_card_balance_agg_numric, on = 'SK_ID_PREV', how = 'left')\ndf_credit_card_balance_agg_categorical = df_previous_application[['SK_ID_PREV', 'SK_ID_CURR']].merge(df_credit_card_balance_agg_categorical, on = 'SK_ID_PREV', how = 'left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# １つの `SK_ID_CURR` に対して、複数の `SK_ID_BUREAU` が存在することになるので、`SK_ID_CURR` を集約\ndf_credit_card_balance_agg_numric = agg_dataframe_numric( df_credit_card_balance_agg_numric.drop(columns = ['SK_ID_PREV']), agg_column = 'SK_ID_CURR', base_column_name = \"credit_card_balance\" )\ndf_credit_card_balance_agg_categorical = agg_dataframe_numric( df_credit_card_balance_agg_categorical.drop(columns = ['SK_ID_PREV']), agg_column = 'SK_ID_CURR', base_column_name = \"credit_card_balance\" )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 元のデータに統合\ndf_train = pd.merge(df_train, df_credit_card_balance_agg_numric, on='SK_ID_CURR', how='left' )\ndf_train = pd.merge(df_train, df_credit_card_balance_agg_categorical, on='SK_ID_CURR', how='left' )\ndf_test = pd.merge(df_test, df_credit_card_balance_agg_numric, on='SK_ID_CURR', how='left' )\ndf_test = pd.merge(df_test, df_credit_card_balance_agg_categorical, on='SK_ID_CURR', how='left' )\ndf_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 不要になったメモリを解放\ndel df_credit_card_balance, df_credit_card_balance_agg_numric, df_credit_card_balance_agg_categorical\ngc.collect()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}